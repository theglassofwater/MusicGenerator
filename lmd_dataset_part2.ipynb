{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import symusic\n",
    "import mido\n",
    "import numpy as np\n",
    "import joblib\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "import seaborn as sns\n",
    "# sns.set_style('white')\n",
    "# sns.set_context('notebook', font_scale=1.5)\n",
    "import matplotlib.gridspec\n",
    "import collections\n",
    "import os\n",
    "from pathlib import Path\n",
    "# plotting.py contains utility functions for making nice histogram plots\n",
    "import util.plotting as plotting\n",
    "from util.play_midi import play_midi\n",
    "from statistics import mean, stdev, variance\n",
    "import random\n",
    "import miditok.\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeac\\Documents\\Uni\\Y3\\Project\n",
      "138174\n"
     ]
    }
   ],
   "source": [
    "if \"lofi_radio\" in os.getcwd().split(os.sep)[-1].lower():\n",
    "    os.chdir(\"..\")\n",
    "\n",
    "# if os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "midi_files = [str(file) for file in Path(\"pretraining_dataset/\").glob(\"**/*.mid\")]\n",
    "print(len(midi_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b3b74acccf498a9782690ef9a7b7f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/675k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeac\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\joeac\\.cache\\huggingface\\hub\\models--theglassofwater--remi_12500. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\joeac\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\miditok\\midi_tokenizer.py:3252: UserWarning: The special token PAD_None is present twice in your configuration. Skipping its duplicated occurrence.\n",
      "  self.config = TokenizerConfig()\n",
      "c:\\Users\\joeac\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\miditok\\classes.py:702: UserWarning: The special token PAD_None is present twice in your configuration. Skipping its duplicated occurrence.\n",
      "  return cls(**input_dict, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = miditok.REMI.from_pretrained(\"theglassofwater/remi_12500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 100_000\n",
    "full_dataset = miditok.pytorch_data.DatasetMIDI(\n",
    "    files_paths=midi_files,\n",
    "    max_seq_len=seq_len+1,  # max_seq_len = start + seq_len + end\n",
    "    tokenizer=tokenizer,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=6)]: Done 188 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=6)]: Done 438 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=6)]: Done 788 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=6)]: Done 1238 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=6)]: Done 1788 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=6)]: Done 2438 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=6)]: Done 3188 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=6)]: Done 4038 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=6)]: Done 4988 tasks      | elapsed: 10.6min\n",
      "[Parallel(n_jobs=6)]: Done 6038 tasks      | elapsed: 12.9min\n",
      "[Parallel(n_jobs=6)]: Done 7188 tasks      | elapsed: 15.4min\n",
      "[Parallel(n_jobs=6)]: Done 8438 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=6)]: Done 9788 tasks      | elapsed: 21.4min\n",
      "[Parallel(n_jobs=6)]: Done 11238 tasks      | elapsed: 24.7min\n",
      "[Parallel(n_jobs=6)]: Done 12788 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=6)]: Done 14438 tasks      | elapsed: 33.3min\n",
      "[Parallel(n_jobs=6)]: Done 16188 tasks      | elapsed: 39.6min\n",
      "[Parallel(n_jobs=6)]: Done 18038 tasks      | elapsed: 48.3min\n",
      "[Parallel(n_jobs=6)]: Done 19988 tasks      | elapsed: 54.9min\n",
      "[Parallel(n_jobs=6)]: Done 22038 tasks      | elapsed: 64.4min\n",
      "[Parallel(n_jobs=6)]: Done 24188 tasks      | elapsed: 71.6min\n",
      "[Parallel(n_jobs=6)]: Done 26438 tasks      | elapsed: 79.1min\n",
      "[Parallel(n_jobs=6)]: Done 28788 tasks      | elapsed: 87.0min\n",
      "[Parallel(n_jobs=6)]: Done 31238 tasks      | elapsed: 95.2min\n",
      "[Parallel(n_jobs=6)]: Done 33788 tasks      | elapsed: 103.6min\n"
     ]
    }
   ],
   "source": [
    "def tokenize_file(file):\n",
    "    try:\n",
    "        tokenized_file = file[\"input_ids\"]\n",
    "        return tokenized_file\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "tokenized_dataset = joblib.Parallel(n_jobs=6, verbose=1)(\n",
    "    joblib.delayed(tokenize_file)(midi_file)\n",
    "    for midi_file in full_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_csv = pd.Dataframe({\"input_id\":tokenized_dataset})\n",
    "hf_csv.to_csv(\"tokenized_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "hf_dataset = load_dataset(\"pretraining_tokenized_dataset\", data_dir=\"Users/joeac/Documents/Uni/Y3/Project/tokenized_dataset.csv\"))\n",
    "hf_dataset.push_to_hub(\"theglassofwater/pretraining_tokenized_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
